# Theory Exploration Bucketing Benchmarks #

This directory contains benchmarks for various algorithmic ways to divide up
ASTs into "buckets", as a divide-and-conquer approach to improving theory
exploration systems.

We use the Theory Exploration Benchmark project, which includes a corpus of
definitions and statements. Subsets of these definitions are sampled
(deterministically), and the properties of those definitions are used as the
ground truth.

## Running Benchmarks ##

We use `asv` to run the benchmarks and manage the results. A suitable
environment can be entered by running `nix-shell` from the root directory of
this repository (i.e. the directory above this `benchmarks/` one).

The usual `asv` commands can be used: `asv run`, `asv publish`, etc.

Our policy is not to commit ASV benchmark results, since they are "derived" data
which can be regenerated programatically (albeit with noise and machine-specific
characteristics).

We only store results from our evaluation script, which uses much more data than
the ASV benchmarks (which are meant to be reasonably fast).
